{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbec7a7-6f89-4bdc-aa43-7c636ad91e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69c12d6-af45-42d8-aba3-3ef5c78c84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "LTA_KEY = os.getenv('LTA_API_KEY')\n",
    "ONEMAP_KEY = os.getenv(\"ONE_MAP_ACCESS_TOKEN\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7373d7",
   "metadata": {},
   "source": [
    "##### 1. LTA Datamall Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c191a0d2-fbaf-4917-affb-26b9779f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GATHERING DATASETS ###\n",
    "\n",
    "def fetch_data(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error fetching data from {url}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    full_path = os.path.join(\"data\", filename)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(full_path, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def download_file(download_url, filename):\n",
    "    \"\"\"Downloads ZIP file from URL, extract content and save as csv.\"\"\"\n",
    "    response = requests.get(download_url, stream = True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        full_path = os.path.join(\"data\", filename)\n",
    "\n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zip_file:\n",
    "            file = zip_file.namelist()[0]   # get the name of first file in the zip\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(zip_file.read(file))\n",
    "            print(f\"Extracted and saved: {full_path}\")\n",
    "    else:\n",
    "        print(f\"Error downloading the file from {download_url}.\")\n",
    "\n",
    "\n",
    "def get_bus_routes(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key,\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    bus_routes_url = \"https://datamall2.mytransport.sg/ltaodataservice/BusRoutes\"\n",
    "    all_bus_routes = []\n",
    "    skip = 0\n",
    "    limit = 500  # Limit per API call\n",
    "\n",
    "    while True:\n",
    "        # Construct the URL with pagination\n",
    "        paginated_url = f\"{bus_routes_url}?$skip={skip}&$top={limit}\"\n",
    "        bus_routes_data = fetch_data(paginated_url, headers)\n",
    "\n",
    "        if bus_routes_data and 'value' in bus_routes_data:\n",
    "            all_bus_routes.extend(bus_routes_data['value'])  # Append new data\n",
    "            \n",
    "            # If the returned data is less than the limit, we have fetched all data\n",
    "            if len(bus_routes_data['value']) < limit:\n",
    "                break\n",
    "            \n",
    "            # Increment the skip value for the next API call\n",
    "            skip += limit\n",
    "        else:\n",
    "            break  # Exit if there was an error or no more data\n",
    "\n",
    "    if all_bus_routes:\n",
    "        save_to_csv(all_bus_routes, \"bus_routes_full.csv\")\n",
    "\n",
    "\n",
    "def get_bus_stops(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key,\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    bus_stops_url = \"https://datamall2.mytransport.sg/ltaodataservice/BusStops\"\n",
    "    all_bus_stops = []\n",
    "    skip = 0\n",
    "    limit = 500  # Limit per API call\n",
    "\n",
    "    while True:\n",
    "        # Construct the URL with pagination\n",
    "        paginated_url = f\"{bus_stops_url}?$skip={skip}&$top={limit}\"\n",
    "        bus_stops_data = fetch_data(paginated_url, headers)\n",
    "\n",
    "        if bus_stops_data and 'value' in bus_stops_data:\n",
    "            all_bus_stops.extend(bus_stops_data['value'])  # Append new data\n",
    "            \n",
    "            # If the returned data is less than the limit, we have fetched all data\n",
    "            if len(bus_stops_data['value']) < limit:\n",
    "                break\n",
    "            \n",
    "            # Increment the skip value for the next API call\n",
    "            skip += limit\n",
    "        else:\n",
    "            break  # Exit if there was an error or no more data\n",
    "\n",
    "    if all_bus_stops:\n",
    "        save_to_csv(all_bus_stops, \"bus_stops_full.csv\")\n",
    "\n",
    "\n",
    "def get_bus_services(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key, \n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    bus_services_url = \"https://datamall2.mytransport.sg/ltaodataservice/BusServices\"\n",
    "    all_bus_services = []\n",
    "    skip = 0\n",
    "    limit = 500  # Limit per API call\n",
    "\n",
    "    while True:\n",
    "        paginated_url = f\"{bus_services_url}?$skip={skip}&$top={limit}\"\n",
    "        bus_services_data = fetch_data(paginated_url, headers)\n",
    "\n",
    "        if bus_services_data and 'value' in bus_services_data:\n",
    "            all_bus_services.extend(bus_services_data['value'])\n",
    "\n",
    "            # If the returned data is less than the limit, we have fetched all data\n",
    "            if len(bus_services_data['value']) < limit:\n",
    "                break\n",
    "            \n",
    "            skip += limit  # Increment the skip value for the next API call\n",
    "        else:\n",
    "            break  # Exit if there was an error or no more data\n",
    "\n",
    "    if all_bus_services:\n",
    "        save_to_csv(all_bus_services, \"bus_services_full.csv\")\n",
    "\n",
    "\n",
    "def get_passenger_volume_by_bus_stops(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key,\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    passenger_volume_bus_stops_url = \"https://datamall2.mytransport.sg/ltaodataservice/PV/Bus\"\n",
    "    response = fetch_data(passenger_volume_bus_stops_url, headers)\n",
    "\n",
    "    if response:\n",
    "        download_link = response.get('value', [{}])[0].get('Link')\n",
    "        if download_link:\n",
    "            download_file(download_link, \"passenger_volume_by_bus_stops.csv\")\n",
    "    else:\n",
    "        print(f\"No data received from the API. Link: {download_link}\")\n",
    "\n",
    "\n",
    "def get_passenger_volume_by_train_stations(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key,\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    passenger_volume_train_stations_url = \"https://datamall2.mytransport.sg/ltaodataservice/PV/Train\"\n",
    "    response = fetch_data(passenger_volume_train_stations_url, headers)\n",
    "\n",
    "    if response:\n",
    "        download_link = response.get('value', [{}])[0].get('Link')\n",
    "        if download_link:\n",
    "            download_file(download_link, \"passenger_volume_by_train_stations.csv\")\n",
    "    else:\n",
    "        print(f\"No data received from the API. Link: {download_link}\")\n",
    "\n",
    "\n",
    "def get_passenger_origin_dest_bus(api_key):\n",
    "    headers = {\n",
    "        \"AccountKey\": api_key,\n",
    "        \"accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    passenger_volume_bus_stops_url = \"https://datamall2.mytransport.sg/ltaodataservice/PV/ODBus\"\n",
    "    response = fetch_data(passenger_volume_bus_stops_url, headers)\n",
    "\n",
    "    if response:\n",
    "        download_link = response.get('value', [{}])[0].get('Link')\n",
    "        if download_link:\n",
    "            download_file(download_link, \"passenger_volume_OD_by_bus_stops.csv\")\n",
    "    else:\n",
    "        print(f\"No data received from the API. Link: {download_link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ea35e-b552-4489-bde1-851cf42b6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bus_routes(LTA_KEY)\n",
    "get_bus_stops(LTA_KEY)\n",
    "get_bus_services(LTA_KEY)\n",
    "get_passenger_volume_by_bus_stops(LTA_KEY)\n",
    "get_passenger_volume_by_train_stations(LTA_KEY)\n",
    "get_passenger_origin_dest_bus(LTA_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa460082",
   "metadata": {},
   "source": [
    "##### 2. Onemap Dataset (MRT Stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84493a2-ead8-403d-8809-8c96fd4108b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "mrt_ranges = {\n",
    "    \"TE\": range(1, 30),\n",
    "    \"NS\": range(1, 29),    # no NS6\n",
    "    \"EW\": range(1, 34),\n",
    "    \"CG\": range(1, 3),\n",
    "    \"NE\": range(1, 19),    # no NE2\n",
    "    \"CC\": range(1, 30),\n",
    "    \"CE\": range(1, 3),\n",
    "    \"DT\": range(1, 36),\n",
    "    \"SW\": range(1, 9),\n",
    "    \"SE\": range(1, 6),\n",
    "    \"PW\": range(1, 8),\n",
    "    \"PE\": range(1, 8)\n",
    "}\n",
    "\n",
    "# Generate the MRT lines\n",
    "list_of_mrt = [f\"{line}{i}\" for line, r in mrt_ranges.items() for i in r]\n",
    "\n",
    "mrt_names = []\n",
    "mrt_lat = []\n",
    "mrt_long = []\n",
    "valid_mrt_list = []\n",
    "\n",
    "for i in range(0, len(list_of_mrt)):\n",
    "    query_address = list_of_mrt[i]\n",
    "    query_string = \"https://www.onemap.gov.sg/api/common/elastic/search?searchVal=\"+str(query_address)+\"&returnGeom=Y&getAddrDetails=Y\"\n",
    "\n",
    "    response = requests.get(query_string)\n",
    "    data_mrt= json.loads(response.content)\n",
    "\n",
    "    if data_mrt['found'] != 0:\n",
    "        station_name = data_mrt[\"results\"][0][\"SEARCHVAL\"]\n",
    "\n",
    "        if \"STATION\" in station_name:\n",
    "            clean_name = re.sub(r\"\\s*\\(.*?\\)\", \"\", station_name)\n",
    "            valid_mrt_list.append(query_address)\n",
    "            mrt_names.append(clean_name)\n",
    "            mrt_lat.append(data_mrt[\"results\"][0][\"LATITUDE\"])\n",
    "            mrt_long.append(data_mrt[\"results\"][0][\"LONGITUDE\"])\n",
    "            print(str(query_address)+\", Latitude: \"+data_mrt[\"results\"][0][\"LATITUDE\"] + \" Longitude: \"+data_mrt[\"results\"][0][\"LONGITUDE\"])\n",
    "\n",
    "# Manually append missing MRT station data\n",
    "manual_data = [\n",
    "    {\"STN_NAME\": \"PASIR RIS MRT STATION\", \"STN_NO\": \"EW1\", \"Latitude\": \"1.372983774\", \"Longitude\": \"103.9492681\"},\n",
    "    {\"STN_NAME\": \"THANGGAM LRT STATION\", \"STN_NO\": \"SW4\", \"Latitude\": \"1.397318155\", \"Longitude\": \"103.8756352\"},\n",
    "    {\"STN_NAME\": \"TONGKANG LRT STATION\", \"STN_NO\": \"SW7\", \"Latitude\": \"1.389347953\", \"Longitude\": \"103.8858441\"}\n",
    "]\n",
    "\n",
    "for entry in manual_data:\n",
    "    mrt_names.append(entry[\"STN_NAME\"])\n",
    "    valid_mrt_list.append(entry[\"STN_NO\"])\n",
    "    mrt_lat.append(entry[\"Latitude\"])\n",
    "    mrt_long.append(entry[\"Longitude\"])\n",
    "\n",
    "mrt_location = pd.DataFrame({\n",
    "    'STN_NAME': mrt_names,\n",
    "    'STN_NO': valid_mrt_list, \n",
    "    'Latitude': mrt_lat, \n",
    "    'Longitude': mrt_long\n",
    "})\n",
    "\n",
    "filename = \"data/mrt_stations.csv\"\n",
    "mrt_location.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
