{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCMamoVOigVd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "import folium\n",
        "from folium import GeoJson\n",
        "from folium import Choropleth\n",
        "from folium.plugins import HeatMap\n",
        "import numpy as np\n",
        "from haversine import haversine, Unit\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from datetime import timedelta\n",
        "import requests\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from geopy.distance import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI0s5Lo9igVe"
      },
      "outputs": [],
      "source": [
        "bus_routes = pd.read_csv(\"data/bus_routes_full.csv\")\n",
        "bus_stops = pd.read_csv(\"data/bus_stops_full.csv\")\n",
        "passenger_volume_OD = pd.read_csv(\"data/passenger_volume_OD.csv\")\n",
        "passenger_volume = pd.read_csv(\"data/passenger_volume.csv\")\n",
        "planning_areas = gpd.read_file(\"data/MasterPlan2019PlanningAreaBoundaryNoSea.geojson\")\n",
        "mrt_stations = pd.read_csv(\"data/mrt_stations.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNvoktBFigVf"
      },
      "outputs": [],
      "source": [
        "bus_routes_combined = pd.merge(bus_routes, bus_stops, on='BusStopCode', how='left')\n",
        "bus_routes_combined.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNQIwL0iigVf"
      },
      "outputs": [],
      "source": [
        "bus_routes_combined['geometry'] = bus_routes_combined.apply(lambda x: Point((x.Longitude, x.Latitude)), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V88Ejf9WigVf",
        "outputId": "e112098d-6ac2-4822-d5ba-fb2d62a77e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ServiceNo Operator  Direction  StopSequence  BusStopCode  Distance  \\\n",
            "0        10     SBST          1             1        75009       0.0   \n",
            "1        10     SBST          1             2        76059       0.6   \n",
            "2        10     SBST          1             3        76069       1.1   \n",
            "3        10     SBST          1             4        96289       2.3   \n",
            "4        10     SBST          1             5        96109       2.7   \n",
            "\n",
            "  WD_FirstBus WD_LastBus SAT_FirstBus SAT_LastBus SUN_FirstBus SUN_LastBus  \\\n",
            "0        0500       2300         0500        2300         0500        2300   \n",
            "1        0502       2302         0502        2302         0502        2302   \n",
            "2        0504       2304         0504        2304         0503        2304   \n",
            "3        0508       2308         0508        2309         0507        2308   \n",
            "4        0509       2310         0509        2311         0508        2309   \n",
            "\n",
            "          RoadName           Description  Latitude   Longitude  \\\n",
            "0  Tampines Ctrl 1          Tampines Int  1.354076  103.943391   \n",
            "1   Tampines Ave 5  Opp Our Tampines Hub  1.352962  103.941652   \n",
            "2   Tampines Ave 5               Blk 147  1.348753  103.942086   \n",
            "3        Simei Ave   Changi General Hosp  1.340055  103.948381   \n",
            "4        Simei Ave          Opp Blk 3012  1.337371  103.950673   \n",
            "\n",
            "                    geometry  \n",
            "0  POINT (103.94339 1.35408)  \n",
            "1  POINT (103.94165 1.35296)  \n",
            "2  POINT (103.94209 1.34875)  \n",
            "3  POINT (103.94838 1.34005)  \n",
            "4  POINT (103.95067 1.33737)  \n"
          ]
        }
      ],
      "source": [
        "bus_routes_combined = gpd.GeoDataFrame(bus_routes_combined, geometry='geometry')\n",
        "\n",
        "bus_routes_combined = bus_routes_combined.set_crs(epsg=4326)\n",
        "\n",
        "print(bus_routes_combined.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzBIi7UVigVg"
      },
      "outputs": [],
      "source": [
        "bus_routes_combined.to_csv(\"data/bus_routes_combined.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d6000DyigVg"
      },
      "outputs": [],
      "source": [
        "routes = (\n",
        "    bus_routes_combined.sort_values(by=['ServiceNo', 'Direction', 'StopSequence'])  # Ensure stops are in the correct order\n",
        "    .groupby(['ServiceNo', 'Direction'])['geometry']\n",
        "    .apply(lambda x: LineString(x.tolist()))  # Create LineString from points\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "bus_routes_ls = gpd.GeoDataFrame(routes, geometry='geometry', crs=\"EPSG:4326\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux4RK2xTigVg",
        "outputId": "9d3726b7-742a-442b-a2d1-b24ed60c4c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ServiceNo  Direction                                           geometry\n",
            "0        10          1  LINESTRING (103.94339 1.35408, 103.94165 1.352...\n",
            "1        10          2  LINESTRING (103.76988 1.29425, 103.76908 1.292...\n",
            "2       100          1  LINESTRING (103.87169 1.35047, 103.87205 1.346...\n",
            "3       100          2  LINESTRING (103.78932 1.31107, 103.78969 1.309...\n",
            "4      100A          1  LINESTRING (103.87169 1.35047, 103.87205 1.346...\n"
          ]
        }
      ],
      "source": [
        "print(bus_routes_ls.head())\n",
        "bus_routes_ls.to_file(\"data/line_string.geojson\", driver='GeoJSON')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn_Jt3NMigVg",
        "outputId": "c7d390b1-d12c-4cd3-c017-acd53086fe98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      STN_NAME STN_NO  Latitude   Longitude LINE  NO\n",
            "0     DHOBY GHAUT MRT STATION     CC1  1.298912  103.846293   CC   1\n",
            "1      BRAS BASAH MRT STATION     CC2  1.296862  103.850667   CC   2\n",
            "2       ESPLANADE MRT STATION     CC3  1.293658  103.855081   CC   3\n",
            "3       PROMENADE MRT STATION     CC4  1.293998  103.860350   CC   4\n",
            "4  NICOLL HIGHWAY MRT STATION     CC5  1.299767  103.863637   CC   5\n"
          ]
        }
      ],
      "source": [
        "# Function to split and duplicate entries\n",
        "def duplicate_entries(df):\n",
        "    # Create an empty list to store new rows\n",
        "    new_rows = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Check if the STN_NO contains a '/'\n",
        "        if '/' in row['STN_NO']:\n",
        "            # Split the STN_NO\n",
        "            lines = row['STN_NO'].split('/')\n",
        "            # Create a new row for each line\n",
        "            for line in lines:\n",
        "                new_row = row.copy()\n",
        "                new_row['STN_NO'] = line.strip()  # Update the STN_NO to the new line\n",
        "                new_rows.append(new_row)\n",
        "        else:\n",
        "            new_rows.append(row)\n",
        "\n",
        "    # Create a new DataFrame from the new rows\n",
        "    return pd.DataFrame(new_rows)\n",
        "\n",
        "# Apply the function to duplicate entries\n",
        "mrt_stations_expanded = duplicate_entries(mrt_stations)\n",
        "\n",
        "mrt_stations_expanded['NO'] = mrt_stations_expanded['NO'].astype(int)\n",
        "\n",
        "mrt_stations_clean = (mrt_stations_expanded.sort_values(['LINE', 'NO']).reset_index(drop=True))\n",
        "\n",
        "print(mrt_stations_clean.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpbAI2OWigVg",
        "outputId": "5da51fc2-7706-4d1a-b3d7-4963e706313e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         STN_NAME STN_NO  Latitude   Longitude LINE  NO  \\\n",
            "171  WOODLANDS NORTH MRT STATION     TE1  1.448292  103.785693   TE   1   \n",
            "172        WOODLANDS MRT STATION     TE2  1.436058  103.787939   TE   2   \n",
            "173  WOODLANDS SOUTH MRT STATION     TE3  1.427396  103.793264   TE   3   \n",
            "174       SPRINGLEAF MRT STATION     TE4  1.397581  103.817857   TE   4   \n",
            "175           LENTOR MRT STATION     TE5  1.385507  103.835744   TE   5   \n",
            "\n",
            "                      geometry  \n",
            "171  POINT (103.78569 1.44829)  \n",
            "172  POINT (103.78794 1.43606)  \n",
            "173   POINT (103.79326 1.4274)  \n",
            "174  POINT (103.81786 1.39758)  \n",
            "175  POINT (103.83574 1.38551)  \n"
          ]
        }
      ],
      "source": [
        "# Create GeoDataFrame for MRT Stations\n",
        "mrt_gdf = gpd.GeoDataFrame(\n",
        "   mrt_stations_clean,\n",
        "    geometry=gpd.points_from_xy(mrt_stations_clean.Longitude, mrt_stations_clean.Latitude),\n",
        "    crs=\"EPSG:4326\"  # WGS84 Latitude/Longitude\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DTL"
      ],
      "metadata": {
        "id": "cetpakhG2wiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DT_stations = mrt_stations[mrt_stations['STN_NO'].str.contains(r'\\bDT', regex=True)]\n",
        "DT_stations = DT_stations.assign(DT_Code=DT_stations['STN_NO'].str.extract(r'(DT\\d+)'))\n",
        "DT_stations = DT_stations.assign(DT_Number = DT_stations['DT_Code'].str.extract(r'(\\d+)').astype(int))\n",
        "DT_sorted = DT_stations.sort_values(by='DT_Number').reset_index(drop=True)\n",
        "DT_sorted = DT_sorted.drop(columns=['DT_Code','DT_Number'])\n",
        "DT_sorted['geometry'] = DT_sorted.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
        "DT_sorted = gpd.GeoDataFrame(DT_sorted, geometry='geometry')\n",
        "\n",
        "route_line = LineString(DT_sorted['geometry'].tolist())\n",
        "DT_ls = gpd.GeoDataFrame({'Line': ['DTL'], 'geometry': [route_line]}, crs=\"EPSG:4326\")\n",
        "\n",
        "DT_ls = DT_ls.to_crs(epsg=32648)\n",
        "bus_routes_ls = bus_routes_ls.to_crs(epsg=32648)\n",
        "\n",
        "DT_buffer_400= DT_ls.buffer(400).union_all()"
      ],
      "metadata": {
        "id": "Kz6CIK4m21Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_overlap(route):\n",
        "    intersection = route.intersection(DT_buffer_400)\n",
        "    overlap_length = intersection.length\n",
        "    route_length = route.length\n",
        "    overlap_percentage = (overlap_length/route_length)*100 if route_length > 0 else 0\n",
        "    return pd.Series({'Overlap Length': overlap_length, 'Overlap Percentage': overlap_percentage})"
      ],
      "metadata": {
        "id": "UVUotyB126xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_overlap(route):\n",
        "    intersection = route.intersection(DT_buffer_400)\n",
        "    overlap_length = intersection.length\n",
        "    route_length = route.length\n",
        "    overlap_percentage = (overlap_length/route_length)*100 if route_length > 0 else 0\n",
        "    return pd.Series({'Overlap Length': overlap_length, 'Overlap Percentage': overlap_percentage})"
      ],
      "metadata": {
        "id": "IDT2JrgW26rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_overlap = buffer_overlap_400.groupby(['ServiceNo', 'Direction'])[['Overlap Length', 'Overlap Percentage']].sum().reset_index()\n",
        "print(service_overlap)"
      ],
      "metadata": {
        "id": "lwn0LWSV26oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_overlap_sorted = service_overlap.sort_values(by='Overlap Percentage', ascending=False)\n",
        "service_overlap_sorted.head(10)"
      ],
      "metadata": {
        "id": "-XbvfiQ326lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top5_overlap = service_overlap_sorted.head(5)['ServiceNo'].tolist()\n",
        "top5_bus_routes = routes[routes['ServiceNo'].isin(top5_overlap)]"
      ],
      "metadata": {
        "id": "HPXxxjib26jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgmap = folium.Map(location=[1.3521, 103.8198], zoom_start=12)\n",
        "\n",
        "coords = [(lat, lon) for lon,lat in route_line.coords]\n",
        "\n",
        "folium.PolyLine(\n",
        "    locations = coords,\n",
        "    color='blue',\n",
        "    weight=5,\n",
        "    opacity=0.8,\n",
        "    tooltip=\"Downtown Line\"\n",
        ").add_to(sgmap)\n",
        "\n",
        "for _,row in DT_sorted.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['STN_NAME'],\n",
        "        icon=folium.Icon(color='blue', icon='train', prefix='fa')\n",
        "    ).add_to(sgmap)\n",
        "\n",
        "map_buffer = route_line.buffer(0.0036)\n",
        "gdf_buffer = gpd.GeoDataFrame(geometry=[map_buffer], crs=DT_sorted.crs)\n",
        "buffer_geojson = gdf_buffer.to_json()\n",
        "\n",
        "folium.GeoJson(\n",
        "    buffer_geojson,\n",
        "    style_function=lambda x: {\n",
        "        'fillColor': 'blue',\n",
        "        'color': 'blue',\n",
        "        'weight': 1,\n",
        "        'fillOpacity': 0.5\n",
        "    },\n",
        ").add_to(sgmap)\n",
        "\n",
        "colors = {\n",
        "    '67':'red',\n",
        "    '23':'green',\n",
        "    '170':'orange'\n",
        "}\n",
        "\n",
        "for _, row in top5_bus_routes.iterrows():\n",
        "    coords = [(lat, lon) for lon,lat in row['geometry'].coords]\n",
        "    folium.PolyLine(\n",
        "        locations = coords,\n",
        "        color=colors.get(row['ServiceNo'], 'black'),\n",
        "        weight=5,\n",
        "        opacity=0.8,\n",
        "        tooltip=f\"{row['ServiceNo']} - Direction {row['Direction']}\"\n",
        "    ).add_to(sgmap)\n",
        "\n",
        "    start_point = coords[0]\n",
        "    end_point = coords[-1]\n",
        "\n",
        "    folium.Marker(location=start_point, icon=folium.Icon(color=colors.get(row['ServiceNo'], 'black'))).add_to(sgmap)\n",
        "    folium.Marker(location=end_point, icon=folium.Icon(color=colors.get(row['ServiceNo'], 'black'))).add_to(sgmap)\n",
        "\n",
        "sgmap"
      ],
      "metadata": {
        "id": "CqUF0-Gh3FVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identified Bus 23"
      ],
      "metadata": {
        "id": "H48Ck5Rk3TGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bus_routes_combined[bus_routes_combined['ServiceNo'] == '23']"
      ],
      "metadata": {
        "id": "lX4xO_wT3FSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgmap2 = folium.Map(location=[1.3521, 103.8198], zoom_start=12)\n",
        "\n",
        "coords = [(lat, lon) for lon,lat in route_line.coords]\n",
        "\n",
        "folium.PolyLine(\n",
        "    locations = coords,\n",
        "    color='blue',\n",
        "    weight=5,\n",
        "    opacity=0.8,\n",
        "    tooltip=\"Downtown Line\"\n",
        ").add_to(sgmap2)\n",
        "\n",
        "for _,row in DT_sorted.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['STN_NAME'],\n",
        "        icon=folium.Icon(color='blue', icon='train', prefix='fa')\n",
        "    ).add_to(sgmap2)\n",
        "\n",
        "# Add Bus 23 stops\n",
        "# these are the first half of the stops\n",
        "for _, row in bus_routes_combined[bus_routes_combined['ServiceNo'] == '23'][:24].iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['BusStopCode'],\n",
        "        icon=folium.Icon(color='red', icon='info-sign')\n",
        "    ).add_to(sgmap2)\n",
        "\n",
        "# these are the 2nd half of the stops\n",
        "for _, row in bus_routes_combined[bus_routes_combined['ServiceNo'] == '23'][24:].iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['BusStopCode'],\n",
        "        icon=folium.Icon(color='green', icon='info-sign')\n",
        "    ).add_to(sgmap2)\n",
        "\n",
        "map_buffer = route_line.buffer(0.0036)\n",
        "gdf_buffer = gpd.GeoDataFrame(geometry=[map_buffer], crs=DT_sorted.crs)\n",
        "buffer_geojson = gdf_buffer.to_json()\n",
        "\n",
        "folium.GeoJson(\n",
        "    buffer_geojson,\n",
        "    style_function=lambda x: {\n",
        "        'fillColor': 'blue',\n",
        "        'color': 'blue',\n",
        "        'weight': 1,\n",
        "        'fillOpacity': 0.5\n",
        "    },\n",
        ").add_to(sgmap2)\n",
        "\n",
        "sgmap2"
      ],
      "metadata": {
        "id": "4vJf1tHW3FQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if there are any alternative bus routes that go from inside the 23 buffer to outside, following the same route as 23 for those stops that are outside the buffer"
      ],
      "metadata": {
        "id": "mC1Je10k3e_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter for Bus 23 stops\n",
        "bus_23_stops = bus_routes_combined[bus_routes_combined['ServiceNo'] == '23'].copy()\n",
        "\n",
        "# Check if the bus stops are within the buffer\n",
        "bus_23_stops['within_dt_buffer'] = bus_23_stops.geometry.apply(\n",
        "    lambda stop: DT_buffer_400.intersects(stop)\n",
        ")\n",
        "\n",
        "# Step 2: Assign groups for outside bus stops\n",
        "bus_23_stops['outside_group'] = (bus_23_stops['within_dt_buffer'] != bus_23_stops['within_dt_buffer'].shift()).cumsum()\n",
        "\n",
        "# Step 3: Get unique outside groups\n",
        "unique_outside_groups_23 = bus_23_stops['outside_group'].dropna().unique()\n",
        "\n",
        "# Step 4: Initialize a dictionary to hold the results for Bus 23\n",
        "other_bus_routes_23 = {}\n",
        "\n",
        "# Step 5: Loop through each outside group to find other bus services\n",
        "for group in unique_outside_groups_23:\n",
        "    # Get bus stop codes for the current outside group\n",
        "    outside_stop_codes_23 = bus_23_stops[bus_23_stops['outside_group'] == group]['BusStopCode'].unique()\n",
        "\n",
        "    # Find the last bus stop that was within the buffer for this group\n",
        "    within_buffer_stops = bus_23_stops[(bus_23_stops['outside_group'] == group) & (bus_23_stops['within_dt_buffer'])]\n",
        "\n",
        "    # Check if there are any stops within the buffer\n",
        "    if not within_buffer_stops.empty:\n",
        "        last_within_buffer_23 = within_buffer_stops.iloc[-1]\n",
        "        last_stop_code_23 = last_within_buffer_23['BusStopCode']\n",
        "\n",
        "        # Step 6: Find other bus routes that service the last stop and the outside stops\n",
        "        other_routes_23 = bus_routes_combined[\n",
        "            bus_routes_combined['BusStopCode'].isin([last_stop_code_23] + list(outside_stop_codes_23))\n",
        "        ]['ServiceNo'].unique()\n",
        "\n",
        "        # Store the results\n",
        "        other_bus_routes_23[group] = other_routes_23\n",
        "    else:\n",
        "        other_bus_routes_23[group] = []  # If there's no valid last stop within the buffer\n",
        "\n",
        "# Step 7: Print the results for Bus 23\n",
        "for group, routes in other_bus_routes_23.items():\n",
        "    print(f\"Outside Group {group} for Bus 23: Other Bus Routes: {routes}\")\n"
      ],
      "metadata": {
        "id": "hFLXMuWu3FN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bus 67"
      ],
      "metadata": {
        "id": "2wIxIjgC40GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "route_67 = routes[routes['ServiceNo'] == '67']\n",
        "bus_67 = bus_routes_combined[bus_routes_combined['ServiceNo'] == '67']\n",
        "bus_67_stops = bus_67[['ServiceNo', 'Direction', 'StopSequence', 'BusStopCode', 'Description', 'Latitude', 'Longitude', 'geometry']]\n",
        "\n",
        "# To find the number of stops within and outside the buffer\n",
        "def stops_within_buffer_by_direction(bus_service, buffer):\n",
        "    results = {}\n",
        "\n",
        "    for direction, group in bus_service.groupby('Direction'):\n",
        "        group['Within Buffer'] = group['geometry'].apply(lambda x: x.within(buffer))\n",
        "\n",
        "        within=group[group['Within Buffer']]\n",
        "        outside=group[~group['Within Buffer']]\n",
        "\n",
        "        results[direction] = {\n",
        "            'within': len(within),\n",
        "            'outside': len(outside),\n",
        "            'within_stops': within,\n",
        "            'outside_stops': outside\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "results_67 = stops_within_buffer_by_direction(bus_67, DT_buffer)\n",
        "for direction, result in results_67.items():\n",
        "    print(f\"Bus 67 - Direction {direction}:\")\n",
        "    print(f\"Stops within buffer: {result['within']}\")\n",
        "    print(f\"Stops outside buffer: {result['outside']}\")\n",
        "\n",
        "within_d1 = results_67[1]['within_stops']\n",
        "outside_d1 = results_67[1]['outside_stops']\n",
        "\n",
        "within_d2 = results_67[2]['within_stops']\n",
        "outside_d2 = results_67[2]['outside_stops']\n"
      ],
      "metadata": {
        "id": "wlJykAQF42kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To add Bus 67's route to the folium map\n",
        "\n",
        "colors = {\n",
        "    1: 'purple',\n",
        "    2: 'darkgreen'\n",
        "}\n",
        "\n",
        "for _,row in route_67.iterrows():\n",
        "    coords = [(lat,lon) for lon,lat in row['geometry'].coords]\n",
        "    direction = row['Direction']\n",
        "    color = colors.get(direction, 'black')\n",
        "\n",
        "    folium.PolyLine(\n",
        "        locations = coords,\n",
        "        color = color,\n",
        "        weight = 4,\n",
        "        opacity = 0.8,\n",
        "        tooltip = f\"Service 67 - Direction {direction}\"\n",
        "    ).add_to(sgmap2)\n",
        "\n",
        "for _, stop in bus_67_stops.iterrows():\n",
        "    stop_coords = [stop.geometry.y, stop.geometry.x]\n",
        "    direction = stop['Direction']\n",
        "    color = colors.get(direction, 'black')\n",
        "\n",
        "    folium.Marker(\n",
        "        location = stop_coords,\n",
        "        popup = f\"Stop: {stop['Description']}<br>Stop Code: {stop['BusStopCode']}\",\n",
        "        tooltip = f\"Bus Stop: {stop['Description']} - Direction {direction}\",\n",
        "        icon = folium.Icon(color=color, icon='bus', prefix='fa')\n",
        "    ).add_to(sgmap2)"
      ],
      "metadata": {
        "id": "B-qDIWDn5i6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Route information from OneMap API"
      ],
      "metadata": {
        "id": "Vo7YRRk63mOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "onemap_api_key = os.getenv('onemap_api_key')"
      ],
      "metadata": {
        "id": "mGipzRLD3FLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import timedelta\n",
        "# Define constant parameters\n",
        "DATE = '10-21-2024'\n",
        "TIME = '08:30:00'\n",
        "MODE = 'TRANSIT'\n",
        "NUM_ITINERARIES = '5'\n",
        "MAX_WALK = '400'\n",
        "\n",
        "# Assume that the API token is defined\n",
        "API_TOKEN = onemap_api_key\n",
        "\n",
        "# Function to get bus route data\n",
        "def get_route(start_coords, end_coords):\n",
        "    url = \"https://www.onemap.gov.sg/api/public/routingsvc/route\"\n",
        "    headers = {\n",
        "        \"Authorization\": API_TOKEN\n",
        "    }\n",
        "    params = {\n",
        "        \"start\": f\"{start_coords[0]},{start_coords[1]}\",\n",
        "        \"end\": f\"{end_coords[0]},{end_coords[1]}\",\n",
        "        \"routeType\": \"pt\",\n",
        "        \"date\": DATE,\n",
        "        \"time\": TIME,\n",
        "        \"mode\": MODE,\n",
        "        \"numItineraries\": NUM_ITINERARIES,\n",
        "        \"maxWalkDistance\": MAX_WALK,\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()  # Return the entire JSON response\n",
        "        else:\n",
        "            print(f\"Error: Received status code {response.status_code}\")\n",
        "            print(f\"Response: {response.text}\")  # Log the response for debugging\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making request to OneMap API: {e}\")\n",
        "    return None\n",
        "\n",
        "def format_duration(seconds):\n",
        "    \"\"\"Convert seconds to a formatted string of hours, minutes, and seconds.\"\"\"\n",
        "    return str(timedelta(seconds=seconds))\n",
        "\n",
        "def print_itineraries(data):\n",
        "    \"\"\"\n",
        "    Extracts and prints itinerary details from OneMap API response data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: dict, the JSON response from the OneMap API, converted to a dictionary.\n",
        "    \"\"\"\n",
        "    # Get the itineraries from the response\n",
        "    itineraries = data.get('plan', {}).get('itineraries', [])\n",
        "\n",
        "    if not itineraries:\n",
        "        print(\"No itineraries found.\")\n",
        "        return\n",
        "\n",
        "    for idx, itinerary in enumerate(itineraries):\n",
        "        # Itinerary-level details\n",
        "        total_duration = itinerary.get('duration', 0)\n",
        "        transit_time = itinerary.get('transitTime', 0)\n",
        "        walk_time = itinerary.get('walkTime', 0)\n",
        "        fare = itinerary.get('fare', 'N/A')\n",
        "\n",
        "        # Format duration and times\n",
        "        formatted_duration = format_duration(total_duration)\n",
        "        formatted_transit_time = format_duration(transit_time)\n",
        "        formatted_walk_time = format_duration(walk_time)\n",
        "        formatted_fare = f\"${fare:.2f}\" if isinstance(fare, (int, float)) else fare\n",
        "\n",
        "        # Print summary of the itinerary\n",
        "        print(f\"\\n--- Itinerary {idx + 1} ---\")\n",
        "        print(f\"Total Duration: {formatted_duration}\")\n",
        "        print(f\"Transit Time: {formatted_transit_time}\")\n",
        "        print(f\"Walk Time: {formatted_walk_time}\")\n",
        "        print(f\"Fare: {formatted_fare}\")\n",
        "\n",
        "        # Iterate over the legs in the itinerary\n",
        "        for leg_idx, leg in enumerate(itinerary.get('legs', [])):\n",
        "            mode = leg.get('mode', 'N/A')\n",
        "            route = leg.get('route', 'N/A')\n",
        "            from_stop = leg.get('from', {}).get('name', 'Unknown')\n",
        "            to_stop = leg.get('to', {}).get('name', 'Unknown')\n",
        "            distance = leg.get('distance', 0)\n",
        "            start_time = leg.get('startTime', 'Unknown')\n",
        "            end_time = leg.get('endTime', 'Unknown')\n",
        "            leggeometry = leg.get('legGeometry', {}).get('points', [])\n",
        "            num_stops = len(leg.get('intermediateStops', []))  # Count intermediate stops\n",
        "\n",
        "            # Print details for each leg\n",
        "            print(f\"\\nLeg {leg_idx + 1}:\")\n",
        "            print(f\"  Mode: {mode}\")\n",
        "            print(f\"  Route: {route if route else 'N/A'}\")\n",
        "            print(f\"  From: {from_stop}\")\n",
        "            print(f\"  To: {to_stop}\")\n",
        "            print(f\"  Distance: {distance:.2f} meters\")\n",
        "            print(f\"  Start Time: {start_time}\")\n",
        "            print(f\"  End Time: {end_time}\")\n",
        "            if num_stops > 0:\n",
        "                print(f\"  Number of Intermediate Stops: {num_stops}\")\n",
        "            else:\n",
        "                print(f\"  No Intermediate Stops\")\n",
        "            if leggeometry:\n",
        "                print(f\"  Leg Geometry: {leggeometry} \")\n",
        "\n",
        "    print(\"\\n--- End of Itineraries ---\")"
      ],
      "metadata": {
        "id": "BrxMgI6z3FJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coordinates(bus_stop_code):\n",
        "    # Look for the row in bus_stops_36B that matches the bus_stop_code\n",
        "    stop = bus_stops[bus_stops['BusStopCode'] == bus_stop_code]\n",
        "\n",
        "    # If a matching row is found, return the coordinates (latitude, longitude)\n",
        "    if not stop.empty:\n",
        "        lat = stop.iloc[0]['Latitude']\n",
        "        lon = stop.iloc[0]['Longitude']\n",
        "        return (lat, lon)\n",
        "    else:\n",
        "        return None  # Return None if the bus stop code is not found"
      ],
      "metadata": {
        "id": "kLJJQOjv3FHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define start and end coordinates\n",
        "#start_coords =  get_coordinates(75229)  # Example starting point\n",
        "start_coords = (1.3463354,103.9339796)\n",
        "#end_coords = get_coordinates(60099)\n",
        "end_coords = (1.3213153,103.8732946)  # Example ending point\n",
        "\n",
        "print(start_coords)\n",
        "print(end_coords)\n",
        "\n",
        "data = get_route(start_coords, end_coords)\n",
        "print(data)\n",
        "print_itineraries(data)  # Call the function to print itineraries"
      ],
      "metadata": {
        "id": "UTLlCKjT3FFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "passenger demand for bus 23"
      ],
      "metadata": {
        "id": "E3rJxzyH3voA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_volume_OD_sept = pd.read_csv(\"data/passenger_volume_OD_by_bus_stops.csv\")\n",
        "passenger_volume_OD_aug = pd.read_csv(\"data/origin_destination_bus_202408.csv\")\n",
        "passenger_volume_OD_july = pd.read_csv(\"data/origin_destination_bus_202407.csv\")\n",
        "\n",
        "# Combine the filtered datasets using pd.concat\n",
        "passenger_volume_OD = pd.concat([passenger_volume_OD_sept,\n",
        "                                       passenger_volume_OD_aug,\n",
        "                                       passenger_volume_OD_july])\n",
        "\n",
        "# Filter for time period 8.0 (8 AM) and weekday\n",
        "filtered_passenger_volume_OD = passenger_volume_OD[\n",
        "    (passenger_volume_OD['TIME_PER_HOUR'].isin([8,9])) &\n",
        "    (passenger_volume_OD[\"DAY_TYPE\"] == \"WEEKDAY\") &\n",
        "    (passenger_volume_OD[\"ORIGIN_PT_CODE\"] == 93019) &\n",
        "    (passenger_volume_OD_sept[\"DESTINATION_PT_CODE\"].isin([2159, 4111, 9022]))\n",
        "]\n",
        "\n",
        "summary = filtered_passenger_volume_OD.groupby(\n",
        "    ['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE', 'TIME_PER_HOUR', 'YEAR_MONTH']\n",
        ").agg({'TOTAL_TRIPS': 'sum'}).reset_index()\n",
        "\n",
        "# Display the summarized data\n",
        "# print(summary)\n",
        "\n",
        "# Pivot the DataFrame to have origin-destination pairs as rows and time-period columns\n",
        "summary_pivot = summary.pivot_table(\n",
        "    index=['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'],  # Rows: origin-destination pairs\n",
        "    columns=['YEAR_MONTH', 'TIME_PER_HOUR'],  # Columns: month and time period\n",
        "    values='TOTAL_TRIPS',  # Values: total trips\n",
        "    aggfunc='sum',  # Aggregation function\n",
        ").fillna(0)  # Fill NaN values with 0 (for combinations with no trips)\n",
        "\n",
        "# Rename the columns to have more descriptive labels (e.g., total_trips_july_8)\n",
        "summary_pivot.columns = [\n",
        "    f\"total_trips_{year_month}_{int(time_hour)}\"\n",
        "    for year_month, time_hour in summary_pivot.columns\n",
        "]\n",
        "\n",
        "# Reset index to make it a regular DataFrame\n",
        "summary_pivot.reset_index(inplace=True)\n",
        "\n",
        "# Display the pivoted DataFrame\n",
        "print(summary_pivot)"
      ],
      "metadata": {
        "id": "iaCxIgRs3FCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "average tap in tap out for 23"
      ],
      "metadata": {
        "id": "KDnINKZO399v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_passenger_demand(bus_routes_combined, passenger_volume, year_month, service_no):\n",
        "    # Filter the passenger_volume DataFrame\n",
        "    passenger_volume_am = passenger_volume[\n",
        "        (passenger_volume['TIME_PER_HOUR'].isin([8, 9])) &\n",
        "        (passenger_volume[\"DAY_TYPE\"] == \"WEEKDAY\") &\n",
        "        (passenger_volume['YEAR_MONTH'] == year_month)\n",
        "    ]\n",
        "\n",
        "    # Group by PT_CODE and sum the relevant passenger volumes\n",
        "    passenger_volume_am = passenger_volume_am.groupby('PT_CODE').agg({\n",
        "        'TOTAL_TAP_IN_VOLUME': 'sum',\n",
        "        'TOTAL_TAP_OUT_VOLUME': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Count the number of services for each bus stop\n",
        "    service_counts = bus_routes_combined.groupby('BusStopCode')['ServiceNo'].nunique().reset_index()\n",
        "    service_counts.columns = ['BusStopCode', 'ServiceCount']\n",
        "\n",
        "    avg_tap_volume = pd.merge(service_counts, passenger_volume_am, left_on=\"BusStopCode\", right_on='PT_CODE', how='left')\n",
        "\n",
        "    # Clean up duplicate PT_CODE columns (from both merges)\n",
        "    avg_tap_volume.drop(columns=['PT_CODE'], inplace=True)\n",
        "\n",
        "    avg_tap_volume['avg_tap_in'] = avg_tap_volume['TOTAL_TAP_IN_VOLUME'] / avg_tap_volume['ServiceCount']\n",
        "    avg_tap_volume['avg_tap_out'] = avg_tap_volume['TOTAL_TAP_OUT_VOLUME'] / avg_tap_volume['ServiceCount']\n",
        "\n",
        "    # Fill NaN values with 0 for average calculations\n",
        "    avg_tap_volume.fillna(0, inplace=True)\n",
        "\n",
        "    avg_tap_volume['avg_tap_in'] = avg_tap_volume['avg_tap_in'].round().astype(int)\n",
        "    avg_tap_volume['avg_tap_out'] = avg_tap_volume['avg_tap_out'].round().astype(int)\n",
        "\n",
        "    bus_stops_passenger_demand = bus_routes_combined.merge(\n",
        "        avg_tap_volume, on='BusStopCode', how='left'\n",
        "    )\n",
        "\n",
        "    # Filter for the specified service number and direction (1)\n",
        "    passenger_demand = bus_stops_passenger_demand[\n",
        "        (bus_stops_passenger_demand['ServiceNo'] == service_no) &\n",
        "        (bus_stops_passenger_demand['Direction'] == 1)\n",
        "    ]\n",
        "\n",
        "    # Ensure the average tap-in volumes are rounded to whole numbers\n",
        "    passenger_demand['avg_tap_in'] = passenger_demand['avg_tap_in'].round()\n",
        "    passenger_demand['avg_tap_out'] = passenger_demand['avg_tap_out'].round()\n",
        "\n",
        "    # Set the last observation of avg_tap_in to 0\n",
        "    passenger_demand['avg_tap_in'].iloc[-1] = 0\n",
        "    passenger_demand['avg_tap_out'].iloc[0] = 0\n",
        "\n",
        "    # Sort the DataFrame by StopSequence for ordered plotting\n",
        "    passenger_demand = passenger_demand.sort_values(by='StopSequence')\n",
        "\n",
        "    # Convert BusStopCode to a categorical variable ordered by StopSequence\n",
        "    passenger_demand['BusStopCode'] = pd.Categorical(passenger_demand['BusStopCode'],\n",
        "                                                       categories=passenger_demand['BusStopCode'].unique(),\n",
        "                                                       ordered=True)\n",
        "\n",
        "    return passenger_demand"
      ],
      "metadata": {
        "id": "hDRhbJxW3FAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get passenger demand data for the three months\n",
        "service_no = \"23\"\n",
        "passenger_demand_23_jul = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-07\", service_no)\n",
        "passenger_demand_23_aug = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-08\", service_no)\n",
        "passenger_demand_23_sept = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-09\", service_no)\n",
        "\n",
        "# Create side-by-side subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot average tap-in volumes\n",
        "axs[0].plot(range(len(passenger_demand_23_jul)), passenger_demand_23_jul['avg_tap_in'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[0].plot(range(len(passenger_demand_23_aug)), passenger_demand_23_aug['avg_tap_in'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[0].plot(range(len(passenger_demand_23_sept)), passenger_demand_23_sept['avg_tap_in'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-in plot\n",
        "axs[0].set_xlabel('Bus Stop Code')\n",
        "axs[0].set_ylabel('Average Tap-In Volume')\n",
        "axs[0].set_title('Average Tap-In Volume for Bus Service 23 by Stop Sequence')\n",
        "axs[0].set_xticks(range(len(passenger_demand_23_jul)))\n",
        "axs[0].set_xticklabels(passenger_demand_23_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[0].grid(axis='y')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot average tap-out volumes\n",
        "axs[1].plot(range(len(passenger_demand_23_jul)), passenger_demand_23_jul['avg_tap_out'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[1].plot(range(len(passenger_demand_23_aug)), passenger_demand_23_aug['avg_tap_out'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[1].plot(range(len(passenger_demand_23_sept)), passenger_demand_23_sept['avg_tap_out'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-out plot\n",
        "axs[1].set_xlabel('Bus Stop Code')\n",
        "axs[1].set_ylabel('Average Tap-Out Volume')\n",
        "axs[1].set_title('Average Tap-Out Volume for Bus Service 23 by Stop Sequence')\n",
        "axs[1].set_xticks(range(len(passenger_demand_23_jul)))\n",
        "axs[1].set_xticklabels(passenger_demand_23_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[1].grid(axis='y')\n",
        "axs[1].legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yooTX-_h3E-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passenger Demand for Bus 67"
      ],
      "metadata": {
        "id": "qfKgJ8oJ6n2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "passenger_volume_OD_sept = pd.read_csv(\"data/passenger_volume_OD_by_bus_stops.csv\")\n",
        "passenger_volume_OD_aug = pd.read_csv(\"data/origin_destination_bus_202408.csv\")\n",
        "passenger_volume_OD_july = pd.read_csv(\"data/origin_destination_bus_202407.csv\")\n",
        "\n",
        "# Combine the filtered datasets using pd.concat\n",
        "passenger_volume_OD = pd.concat([passenger_volume_OD_sept,\n",
        "                                       passenger_volume_OD_aug,\n",
        "                                       passenger_volume_OD_july])\n",
        "\n",
        "# Filter for time period 8.0 (8 AM) and weekday\n",
        "filtered_passenger_volume_OD = passenger_volume_OD[\n",
        "    (passenger_volume_OD['TIME_PER_HOUR'].isin([8,9])) &\n",
        "    (passenger_volume_OD[\"DAY_TYPE\"] == \"WEEKDAY\") &\n",
        "    (passenger_volume_OD[\"ORIGIN_PT_CODE\"] == 44009) &\n",
        "    (passenger_volume_OD_sept[\"DESTINATION_PT_CODE\"].isin([2159, 4111, 9022]))\n",
        "]\n",
        "\n",
        "summary = filtered_passenger_volume_OD.groupby(\n",
        "    ['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE', 'TIME_PER_HOUR', 'YEAR_MONTH']\n",
        ").agg({'TOTAL_TRIPS': 'sum'}).reset_index()\n",
        "\n",
        "# Display the summarized data\n",
        "# print(summary)\n",
        "\n",
        "# Pivot the DataFrame to have origin-destination pairs as rows and time-period columns\n",
        "summary_pivot = summary.pivot_table(\n",
        "    index=['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE'],  # Rows: origin-destination pairs\n",
        "    columns=['YEAR_MONTH', 'TIME_PER_HOUR'],  # Columns: month and time period\n",
        "    values='TOTAL_TRIPS',  # Values: total trips\n",
        "    aggfunc='sum',  # Aggregation function\n",
        ").fillna(0)  # Fill NaN values with 0 (for combinations with no trips)\n",
        "\n",
        "# Rename the columns to have more descriptive labels (e.g., total_trips_july_8)\n",
        "summary_pivot.columns = [\n",
        "    f\"total_trips_{year_month}_{int(time_hour)}\"\n",
        "    for year_month, time_hour in summary_pivot.columns\n",
        "]\n",
        "\n",
        "# Reset index to make it a regular DataFrame\n",
        "summary_pivot.reset_index(inplace=True)\n",
        "\n",
        "# Display the pivoted DataFrame\n",
        "print(summary_pivot)"
      ],
      "metadata": {
        "id": "VCvHW-Fs6rrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get passenger demand data for the three months\n",
        "service_no = \"67\"\n",
        "passenger_demand_67_jul = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-07\", service_no)\n",
        "passenger_demand_67_aug = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-08\", service_no)\n",
        "passenger_demand_67_sept = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-09\", service_no)\n",
        "\n",
        "# Create side-by-side subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot average tap-in volumes\n",
        "axs[0].plot(range(len(passenger_demand_67_jul)), passenger_demand_67_jul['avg_tap_in'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[0].plot(range(len(passenger_demand_67_aug)), passenger_demand_67_aug['avg_tap_in'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[0].plot(range(len(passenger_demand_67_sept)), passenger_demand_67_sept['avg_tap_in'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-in plot\n",
        "axs[0].set_xlabel('Bus Stop Code')\n",
        "axs[0].set_ylabel('Average Tap-In Volume')\n",
        "axs[0].set_title('Average Tap-In Volume for Bus Service 67 by Stop Sequence')\n",
        "axs[0].set_xticks(range(len(passenger_demand_67_jul)))\n",
        "axs[0].set_xticklabels(passenger_demand_67_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[0].grid(axis='y')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot average tap-out volumes\n",
        "axs[1].plot(range(len(passenger_demand_67_jul)), passenger_demand_67_jul['avg_tap_out'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[1].plot(range(len(passenger_demand_67_aug)), passenger_demand_67_aug['avg_tap_out'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[1].plot(range(len(passenger_demand_67_sept)), passenger_demand_67_sept['avg_tap_out'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-out plot\n",
        "axs[1].set_xlabel('Bus Stop Code')\n",
        "axs[1].set_ylabel('Average Tap-Out Volume')\n",
        "axs[1].set_title('Average Tap-Out Volume for Bus Service 67 by Stop Sequence')\n",
        "axs[1].set_xticks(range(len(passenger_demand_67_jul)))\n",
        "axs[1].set_xticklabels(passenger_demand_67_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[1].grid(axis='y')\n",
        "axs[1].legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_lay"
      ],
      "metadata": {
        "id": "OGjkdO843E7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teline_gdf = mrt_gdf[mrt_gdf[\"LINE\"] == \"TE\"]\n",
        "\n",
        "# Display the first few rows to confirm the result\n",
        "print(teline_gdf.head())\n",
        "\n",
        "teline_gdf.to_file(\"data/teline_gdf.geojson\", driver='GeoJSON')\n",
        "\n",
        "route_line = LineString(teline_gdf['geometry'].tolist())\n",
        "TE_ls = gpd.GeoDataFrame({'Line': ['MRT'], 'geometry': [route_line]}, crs=\"EPSG:4326\")\n",
        "\n",
        "TE_ls.to_file(\"data/TE_ls.geojson\", driver='GeoJSON')\n",
        "\n",
        "TE_ls = TE_ls.to_crs(epsg=32648)\n",
        "bus_routes_ls = bus_routes_ls.to_crs(epsg=32648)\n",
        "\n",
        "TE_buffer_400= TE_ls.buffer(400).union_all()\n",
        "print(TE_buffer_400)\n",
        "\n",
        "# Plotting the polygon\n",
        "fig, ax = plt.subplots()\n",
        "x, y = TE_buffer_400.exterior.xy  # Extract x and y coordinates\n",
        "ax.plot(x, y, color='blue', linewidth=2)  # Plot the polygon outline\n",
        "ax.fill(x, y, color='skyblue', alpha=0.5)  # Optional: Fill the polygon with color\n",
        "\n",
        "# Set plot title and labels\n",
        "ax.set_title('Polygon Plot')\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y1cMkT2XkUF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKIWH3CdzPKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the overlap between bus routes and TEL buffer"
      ],
      "metadata": {
        "id": "enPkIqvFlHrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt5BWEhfigVh"
      },
      "outputs": [],
      "source": [
        "def calculate_overlap(route, buffer):\n",
        "    intersection = route.intersection(buffer)\n",
        "    overlap_length = intersection.length\n",
        "    route_length = route.length\n",
        "    overlap_percentage = (overlap_length / route_length) * 100 if route_length > 0 else 0\n",
        "    return pd.Series({'Overlap Length': overlap_length, 'Overlap Percentage': overlap_percentage})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the top 10 bus routes with the most overlap with TEL"
      ],
      "metadata": {
        "id": "aKRsbR71m9vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMT36bzWigVh"
      },
      "outputs": [],
      "source": [
        "\n",
        "TEL_buffer_overlap_400 = bus_routes_ls.copy()\n",
        "\n",
        "TEL_buffer_overlap_400[['Overlap Length', 'Overlap Percentage']] = TEL_buffer_overlap_400['geometry'].apply(calculate_overlap, buffer=TE_buffer_400)\n",
        "\n",
        "# print(TEL_buffer_overlap_400.head())\n",
        "\n",
        "TEL_service_overlap = TEL_buffer_overlap_400.groupby(['ServiceNo', 'Direction'])[['Overlap Length', 'Overlap Percentage']].sum().reset_index()\n",
        "# print(TEL_service_overlap)\n",
        "\n",
        "TEL_service_overlap_sorted = TEL_service_overlap.sort_values(by='Overlap Percentage', ascending=False)\n",
        "TEL_service_overlap_sorted.head(10)\n",
        "\n",
        "TEL_top10_overlap = TEL_service_overlap_sorted.head(10)['ServiceNo'].tolist()\n",
        "TEL_top10_bus_routes = routes[routes['ServiceNo'].isin(TEL_top10_overlap)]\n",
        "print(TEL_top10_bus_routes)\n",
        "\n",
        "#TEL_top10_bus_routes.to_file(\"data/top5_bus_routes.geojson\", driver=\"GeoJSON\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DTL\n",
        "buffer_overlap_400 = bus_routes_ls.copy()\n",
        "buffer_overlap_400[['Overlap Length', 'Overlap Percentage']] = buffer_overlap_400['geometry'].apply(calculate_overlap)\n",
        "service_overlap = buffer_overlap_400.groupby(['ServiceNo', 'Direction'])[['Overlap Length', 'Overlap Percentage']].sum().reset_index()\n",
        "#print(service_overlap)\n",
        "service_overlap_sorted = service_overlap.sort_values(by='Overlap Percentage', ascending=False)\n",
        "service_overlap_sorted.head(10)"
      ],
      "metadata": {
        "id": "XDf9LlwZzFWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering the bus routes for the shortlisted bus services"
      ],
      "metadata": {
        "id": "Li4x_1wTohXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9JJdn9iigVh"
      },
      "outputs": [],
      "source": [
        "TEL_interested_busroutes = TEL_top10_bus_routes[\n",
        "    (TEL_top10_bus_routes[\"ServiceNo\"].isin(['36B', '47', '196e', '901'])) &\n",
        "    (TEL_top10_bus_routes[\"Direction\"] == 1)\n",
        "]\n",
        "\n",
        "TEL_bus_routes_combined_filtered = bus_routes_combined[\n",
        "    bus_routes_combined[['ServiceNo', 'Direction']].apply(tuple, axis=1).isin(TEL_interested_busroutes[['ServiceNo', 'Direction']].apply(tuple, axis=1))\n",
        "]\n",
        "\n",
        "# print(TEL_bus_routes_combined_filtered.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dtl\n",
        "top5_overlap = service_overlap_sorted.head(5)['ServiceNo'].tolist()\n",
        "top5_bus_routes = routes[routes['ServiceNo'].isin(top5_overlap)]"
      ],
      "metadata": {
        "id": "qrYe75Xb0G8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qvU6EmqigVh"
      },
      "outputs": [],
      "source": [
        "# Function to check if a bus stop point is within the buffer\n",
        "def is_within_buffer(bus_stop):\n",
        "    return TE_buffer_400.contains(bus_stop)\n",
        "\n",
        "# Create a new column 'Within_Buffer' for all bus routes\n",
        "TEL_bus_routes_combined_filtered['Within_Buffer'] = bus_routes_combined['geometry'].apply(lambda x: TE_buffer_400.contains(x))\n",
        "\n",
        "# Display the DataFrame with the new column\n",
        "print(TEL_bus_routes_combined_filtered[['ServiceNo', 'Direction', 'geometry', 'Within_Buffer']].head())\n",
        "\n",
        "# Count the number of bus stops within the buffer for each bus route\n",
        "bus_stops_within_buffer_count = TEL_bus_routes_combined_filtered[TEL_bus_routes_combined_filtered['Within_Buffer']].groupby('ServiceNo').size().reset_index(name='Count_With_Buffer')\n",
        "\n",
        "# Count the total number of bus stops for each bus route\n",
        "total_bus_stops_count = TEL_bus_routes_combined_filtered.groupby('ServiceNo').size().reset_index(name='Total_Count')\n",
        "\n",
        "# Merge the two DataFrames on 'ServiceNo'\n",
        "bus_stops_summary = pd.merge(total_bus_stops_count, bus_stops_within_buffer_count, on='ServiceNo', how='left')\n",
        "\n",
        "# Fill NaN values with 0 for routes that have no stops within the buffer\n",
        "bus_stops_summary['Count_With_Buffer'] = bus_stops_summary['Count_With_Buffer'].fillna(0)\n",
        "\n",
        "# Display the summary DataFrame\n",
        "print(bus_stops_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DTL map showing most overlapping bus routes"
      ],
      "metadata": {
        "id": "uCk91P0Z0oWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgmap = folium.Map(location=[1.3521, 103.8198], zoom_start=12)\n",
        "\n",
        "coords = [(lat, lon) for lon,lat in route_line.coords]\n",
        "\n",
        "folium.PolyLine(\n",
        "    locations = coords,\n",
        "    color='blue',\n",
        "    weight=5,\n",
        "    opacity=0.8,\n",
        "    tooltip=\"Downtown Line\"\n",
        ").add_to(sgmap)\n",
        "\n",
        "for _,row in DT_sorted.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        popup=row['STN_NAME'],\n",
        "        icon=folium.Icon(color='blue', icon='train', prefix='fa')\n",
        "    ).add_to(sgmap)"
      ],
      "metadata": {
        "id": "XUO2PCUz0n5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_overlaplength_sorted = service_overlap.sort_values(by='Overlap Length', ascending=False)\n",
        "service_overlaplength_sorted.head(10)"
      ],
      "metadata": {
        "id": "wff7BbgL1FIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identified bus service 36B for removal"
      ],
      "metadata": {
        "id": "sQ1z5PPGpRaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQIWxwpPigVh"
      },
      "outputs": [],
      "source": [
        "\n",
        "bus_stops_36B = bus_routes_combined[\n",
        "        (bus_routes_combined['ServiceNo'] == \"36B\") &\n",
        "        (bus_routes_combined['Direction'] == 1)\n",
        "    ]\n",
        "\n",
        "bus_stop_codes_36B = bus_stops_36B['BusStopCode'].unique().tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40bKGS8FigVi"
      },
      "outputs": [],
      "source": [
        "from geopy.distance import geodesic\n",
        "\n",
        "def find_nearest_mrt(bus_stop_row, mrt_stations):\n",
        "    bus_stop_location = (bus_stop_row['Latitude'], bus_stop_row['Longitude'])\n",
        "\n",
        "    # Calculate distances to all MRT stations and find the nearest one\n",
        "    mrt_stations['Distance'] = mrt_stations.apply(\n",
        "        lambda row: geodesic(bus_stop_location, (row['Latitude'], row['Longitude'])).m,  # Ensure .m is used for meters\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Find the nearest MRT station by selecting the station with the minimum distance\n",
        "    nearest_station = mrt_stations.loc[mrt_stations['Distance'].idxmin()]\n",
        "\n",
        "    return nearest_station['STN_NO'], nearest_station['Distance']\n",
        "\n",
        "# Apply the function to each bus stop and expand the results into two new columns\n",
        "bus_stops_36B[['Nearest_MRT_Station', 'Distance_to_MRT']] = bus_stops_36B.apply(\n",
        "    find_nearest_mrt, mrt_stations=mrt_gdf, axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "# Add a new column 'Near_MRT' based on the distance to MRT\n",
        "bus_stops_36B['Near_MRT'] = bus_stops_36B['Distance_to_MRT'] <= 400\n",
        "\n",
        "# Display or work with the updated DataFrame\n",
        "print(bus_stops_36B.head())\n",
        "\n",
        "# Count the number of bus stops that are near MRT stations\n",
        "count_near_mrt = bus_stops_36B['Near_MRT'].sum()\n",
        "\n",
        "# Display the count\n",
        "print(f\"Number of bus stops near MRT stations: {count_near_mrt}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXs9OaLiigVi"
      },
      "outputs": [],
      "source": [
        "\n",
        "bus_stops_36B = pd.merge(\n",
        "    bus_stops_36B,\n",
        "    mrt_stations[['STN_NO', 'STN_NAME']],\n",
        "    left_on='Nearest_MRT_Station',\n",
        "    right_on='STN_NO',\n",
        "    how='left'\n",
        ").drop(columns=['STN_NO'])\n",
        "\n",
        "# bus_stops_36B.to_csv('data/bus_stops_36B.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to find direct routes between 2 bus stops"
      ],
      "metadata": {
        "id": "J_n3ja0VvPvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llpy26vQigVi"
      },
      "outputs": [],
      "source": [
        "\n",
        "def find_routes(bus_routes_combined, start_bus_stop, end_bus_stop, exclude_routes=None):\n",
        "\n",
        "    # Convert exclude_routes to a set if None is provided\n",
        "    if exclude_routes is None:\n",
        "        exclude_routes = set()\n",
        "\n",
        "    # Find all routes serving the start and end bus stops\n",
        "    routes_from_start = bus_routes_combined[\n",
        "        bus_routes_combined['BusStopCode'] == start_bus_stop]['ServiceNo'].unique()\n",
        "\n",
        "    routes_from_end = bus_routes_combined[\n",
        "        bus_routes_combined['BusStopCode'] == end_bus_stop]['ServiceNo'].unique()\n",
        "\n",
        "    # Exclude specified routes from the lists\n",
        "    routes_from_start = set(routes_from_start) - exclude_routes\n",
        "    routes_from_end = set(routes_from_end) - exclude_routes\n",
        "\n",
        "    # Check for direct routes\n",
        "    direct_routes = routes_from_start.intersection(routes_from_end)\n",
        "\n",
        "    if direct_routes:\n",
        "        print(f\"Direct routes between {start_bus_stop} and {end_bus_stop}: {direct_routes}\")\n",
        "    else:\n",
        "        print(f\"No direct routes. Searching for alternative transfer routes...\")\n",
        "\n",
        "        # Find possible transfer points\n",
        "        routes_from_start_df = bus_routes_combined[\n",
        "            bus_routes_combined['ServiceNo'].isin(routes_from_start)]\n",
        "\n",
        "        routes_from_end_df = bus_routes_combined[\n",
        "            bus_routes_combined['ServiceNo'].isin(routes_from_end)]\n",
        "\n",
        "        # Merge to find common transfer stops\n",
        "        transfer_stops = pd.merge(\n",
        "            routes_from_start_df, routes_from_end_df,\n",
        "            on='BusStopCode', suffixes=('_start', '_end')\n",
        "        )\n",
        "\n",
        "        if not transfer_stops.empty:\n",
        "            print(\"Transfer points and routes:\")\n",
        "            print(transfer_stops[['BusStopCode', 'ServiceNo_start', 'ServiceNo_end']].drop_duplicates())\n",
        "        else:\n",
        "            print(\"No valid transfer points found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "API call to obtain token for OneMap routing API"
      ],
      "metadata": {
        "id": "2r03vgWpvUP3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbNkQRbcigVi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "\n",
        "# Set the URL and headers\n",
        "url = \"https://developers.onemap.sg/privateapi/auth/post/getToken\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"email\": \"\",\n",
        "    \"password\": \"\"\n",
        "}\n",
        "\n",
        "# Send POST request\n",
        "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "# Check if request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the JSON response\n",
        "    data = response.json()\n",
        "    access_token = data['access_token']\n",
        "    expiry_timestamp = data['expiry_timestamp']\n",
        "\n",
        "    print(f\"Access Token: {access_token}\")\n",
        "    print(f\"Expiry: {expiry_timestamp}\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve token. Status code: {response.status_code}\")\n",
        "    print(f\"Response: {response.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get onemap routes"
      ],
      "metadata": {
        "id": "_lJnjgG-yy5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SARP5EYOigVi"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "onemap_api_key = os.getenv('OneMap_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVLz0TV2igVi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Define constant parameters\n",
        "DATE = '10-21-2024'\n",
        "TIME = '08:30:00'\n",
        "MODE = 'TRANSIT'\n",
        "NUM_ITINERARIES = '3'\n",
        "MAX_WALK = '400'\n",
        "\n",
        "API_TOKEN = onemap_api_key\n",
        "\n",
        "# Function to get bus route data\n",
        "def get_route(start_coords, end_coords):\n",
        "    url = \"https://www.onemap.gov.sg/api/public/routingsvc/route\"\n",
        "    headers = {\n",
        "        \"Authorization\": API_TOKEN\n",
        "    }\n",
        "    params = {\n",
        "        \"start\": f\"{start_coords[0]},{start_coords[1]}\",\n",
        "        \"end\": f\"{end_coords[0]},{end_coords[1]}\",\n",
        "        \"routeType\": \"pt\",\n",
        "        \"date\": DATE,\n",
        "        \"time\": TIME,\n",
        "        \"mode\": MODE,\n",
        "        \"numItineraries\": NUM_ITINERARIES,\n",
        "        \"maxWalkDistance\": MAX_WALK,\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()  # Return the entire JSON response\n",
        "        else:\n",
        "            print(f\"Error: Received status code {response.status_code}\")\n",
        "            print(f\"Response: {response.text}\")  # Log the response for debugging\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making request to OneMap API: {e}\")\n",
        "    return None\n",
        "\n",
        "def format_duration(seconds):\n",
        "    \"\"\"Convert seconds to a formatted string of hours, minutes, and seconds.\"\"\"\n",
        "    return str(timedelta(seconds=seconds))\n",
        "\n",
        "def print_itineraries(data):\n",
        "    \"\"\"\n",
        "    Extracts and prints itinerary details from OneMap API response data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: dict, the JSON response from the OneMap API, converted to a dictionary.\n",
        "    \"\"\"\n",
        "    # Get the itineraries from the response\n",
        "    itineraries = data.get('plan', {}).get('itineraries', [])\n",
        "\n",
        "    if not itineraries:\n",
        "        print(\"No itineraries found.\")\n",
        "        return\n",
        "\n",
        "    for idx, itinerary in enumerate(itineraries):\n",
        "        # Itinerary-level details\n",
        "        total_duration = itinerary.get('duration', 0)\n",
        "        transit_time = itinerary.get('transitTime', 0)\n",
        "        walk_time = itinerary.get('walkTime', 0)\n",
        "        fare = itinerary.get('fare', 'N/A')\n",
        "\n",
        "        # Format duration and times\n",
        "        formatted_duration = format_duration(total_duration)\n",
        "        formatted_transit_time = format_duration(transit_time)\n",
        "        formatted_walk_time = format_duration(walk_time)\n",
        "        formatted_fare = f\"${fare:.2f}\" if isinstance(fare, (int, float)) else fare\n",
        "\n",
        "        # Print summary of the itinerary\n",
        "        print(f\"\\n--- Itinerary {idx + 1} ---\")\n",
        "        print(f\"Total Duration: {formatted_duration}\")\n",
        "        print(f\"Transit Time: {formatted_transit_time}\")\n",
        "        print(f\"Walk Time: {formatted_walk_time}\")\n",
        "        print(f\"Fare: {formatted_fare}\")\n",
        "\n",
        "        # Iterate over the legs in the itinerary\n",
        "        for leg_idx, leg in enumerate(itinerary.get('legs', [])):\n",
        "            mode = leg.get('mode', 'N/A')\n",
        "            route = leg.get('route', 'N/A')\n",
        "            from_stop = leg.get('from', {}).get('name', 'Unknown')\n",
        "            to_stop = leg.get('to', {}).get('name', 'Unknown')\n",
        "            distance = leg.get('distance', 0)\n",
        "            start_time = leg.get('startTime', 'Unknown')\n",
        "            end_time = leg.get('endTime', 'Unknown')\n",
        "            leggeometry = leg.get('legGeometry', {}).get('points', [])\n",
        "            num_stops = len(leg.get('intermediateStops', []))  # Count intermediate stops\n",
        "\n",
        "            # Print details for each leg\n",
        "            print(f\"\\nLeg {leg_idx + 1}:\")\n",
        "            print(f\"  Mode: {mode}\")\n",
        "            print(f\"  Route: {route if route else 'N/A'}\")\n",
        "            print(f\"  From: {from_stop}\")\n",
        "            print(f\"  To: {to_stop}\")\n",
        "            print(f\"  Distance: {distance:.2f} meters\")\n",
        "            print(f\"  Start Time: {start_time}\")\n",
        "            print(f\"  End Time: {end_time}\")\n",
        "            if num_stops > 0:\n",
        "                print(f\"  Number of Intermediate Stops: {num_stops}\")\n",
        "            else:\n",
        "                print(f\"  No Intermediate Stops\")\n",
        "            if leggeometry:\n",
        "                print(f\"  Leg Geometry: {leggeometry} \")\n",
        "\n",
        "    print(\"\\n--- End of Itineraries ---\")\n",
        "\n",
        "def get_coordinates(bus_stop_code):\n",
        "    # Look for the row in bus_stops_36B that matches the bus_stop_code\n",
        "    stop = bus_stops[bus_stops['BusStopCode'] == bus_stop_code]\n",
        "\n",
        "    # If a matching row is found, return the coordinates (latitude, longitude)\n",
        "    if not stop.empty:\n",
        "        lat = stop.iloc[0]['Latitude']\n",
        "        lon = stop.iloc[0]['Longitude']\n",
        "        return (lat, lon)\n",
        "    else:\n",
        "        return None  # Return None if the bus stop code is not found\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RS2D6pKVyvWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYi7R0bqigVj"
      },
      "outputs": [],
      "source": [
        "# Define start and end coordinates\n",
        "start_coords =  get_coordinates(93019)  # Example starting point\n",
        "end_coords = (1.292936722,103.8525856)  # Example ending point\n",
        "\n",
        "data = get_route(start_coords, end_coords)\n",
        "print_itineraries(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create passenger volume datasets"
      ],
      "metadata": {
        "id": "-MpPo6Acyrb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58hk0skbigVj"
      },
      "outputs": [],
      "source": [
        "passenger_volume_am = passenger_volume[\n",
        "    (passenger_volume['TIME_PER_HOUR'].isin([8,9])) &\n",
        "    (passenger_volume[\"DAY_TYPE\"] == \"WEEKDAY\")]\n",
        "\n",
        "\n",
        "passenger_volume_pm = passenger_volume[\n",
        "    (passenger_volume['TIME_PER_HOUR'].isin([5,6])) &\n",
        "    (passenger_volume[\"DAY_TYPE\"] == \"WEEKDAY\")]\n",
        "\n",
        "# Group by PT_CODE and aggregate both TOTAL_TAP_IN_VOLUME and TOTAL_TAP_OUT_VOLUME\n",
        "tap_volume_am = passenger_volume_am.groupby('PT_CODE').agg({\n",
        "    'TOTAL_TAP_IN_VOLUME': 'sum',\n",
        "    'TOTAL_TAP_OUT_VOLUME': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Same for the PM period\n",
        "tap_volume_pm = passenger_volume_pm.groupby('PT_CODE').agg({\n",
        "    'TOTAL_TAP_IN_VOLUME': 'sum',\n",
        "    'TOTAL_TAP_OUT_VOLUME': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "tap_volume_am.rename(columns={\n",
        "    'TOTAL_TAP_IN_VOLUME': 'TOTAL_TAP_IN_VOLUME_am',\n",
        "    'TOTAL_TAP_OUT_VOLUME': 'TOTAL_TAP_OUT_VOLUME_am'\n",
        "}, inplace=True)\n",
        "\n",
        "# Rename the columns in the PM dataset\n",
        "tap_volume_pm.rename(columns={\n",
        "    'TOTAL_TAP_IN_VOLUME': 'TOTAL_TAP_IN_VOLUME_pm',\n",
        "    'TOTAL_TAP_OUT_VOLUME': 'TOTAL_TAP_OUT_VOLUME_pm'\n",
        "}, inplace=True)\n",
        "\n",
        "# Merge the passenger demand with bus stops\n",
        "bus_stops_passenger_demand = bus_routes_combined.merge(\n",
        "    tap_volume_am, left_on='BusStopCode', right_on='PT_CODE', how='left'\n",
        ")\n",
        "# Merge again with tap volume for PM period and add suffixes for PM columns\n",
        "bus_stops_passenger_demand = bus_stops_passenger_demand.merge(\n",
        "    tap_volume_pm, left_on='BusStopCode', right_on='PT_CODE', how='left', suffixes=('', '_pm'),\n",
        ")\n",
        "\n",
        "# Clean up duplicate PT_CODE columns (from both merges)\n",
        "bus_stops_passenger_demand.drop(columns=['PT_CODE', 'PT_CODE_pm'], inplace=True)\n",
        "\n",
        "bus_stops_gdf = gpd.GeoDataFrame(bus_stops_passenger_demand, geometry='geometry', crs=\"EPSG:4326\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tap in tap out map"
      ],
      "metadata": {
        "id": "BugBfG1aymJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-ja1NAeigVj"
      },
      "outputs": [],
      "source": [
        "planning_areas = gpd.read_file(\"data/MasterPlan2019PlanningAreaBoundaryNoSea.geojson\")\n",
        "\n",
        "# Extract sub zone\n",
        "planning_areas['sub_zone'] = planning_areas['Description'].str.extract(r'<th>SUBZONE_N</th>\\s*<td>(.*?)</td>', expand=False).str.lower()\n",
        "\n",
        "# Extract planning area\n",
        "planning_areas['planning_area'] = planning_areas['Description'].str.extract(r'<th>PLN_AREA_N</th>\\s*<td>(.*?)</td>', expand=False).str.lower()\n",
        "\n",
        "# Extract region\n",
        "planning_areas['region'] = planning_areas['Description'].str.extract(r'<th>REGION_N</th>\\s*<td>(.*?)</td>', expand=False).str.lower()\n",
        "\n",
        "planning_areas = planning_areas.to_crs(epsg=32648)\n",
        "bus_stops_gdf = bus_stops_gdf.to_crs(epsg=32648)\n",
        "\n",
        "bus_within_areas = gpd.sjoin(bus_stops_gdf, planning_areas, how=\"inner\", predicate=\"within\")\n",
        "\n",
        "total_tap_in_volume_am = bus_within_areas.groupby('planning_area').agg(total_tap_in_volume_am=('TOTAL_TAP_IN_VOLUME_am', 'mean')).reset_index()\n",
        "total_tap_out_volume_am = bus_within_areas.groupby('planning_area').agg(total_tap_out_volume_am=('TOTAL_TAP_OUT_VOLUME_am', 'mean')).reset_index()\n",
        "\n",
        "tap_in_am = planning_areas.merge(total_tap_in_volume_am, on='planning_area', how='left')\n",
        "tap_out_am = planning_areas.merge(total_tap_out_volume_am, on='planning_area', how='left')\n",
        "\n",
        "# Fill NaN with 0 if necessary\n",
        "tap_in_am['total_tap_in_volume_am'].fillna(0, inplace=True)\n",
        "tap_out_am['total_tap_out_volume_am'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert planning areas GeoDataFrame to GeoJSON for Folium\n",
        "tap_in_am_geojson = tap_in_am.to_crs(epsg=4326).to_json()\n",
        "tap_out_am_geojson = tap_out_am.to_crs(epsg=4326).to_json()\n",
        "\n",
        "# Initialize map centered around Singapore\n",
        "tap_in_am_map = folium.Map(location=[1.3521, 103.8198], zoom_start=11)\n",
        "\n",
        "# Add choropleth layer for total tap-in volume\n",
        "Choropleth(\n",
        "    geo_data=tap_in_am_geojson,\n",
        "    data=tap_in_am,\n",
        "    columns=['planning_area', 'total_tap_in_volume_am'],\n",
        "    key_on='feature.properties.planning_area',\n",
        "    fill_color='YlGnBu',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name='Total Tap-In Volume AM',\n",
        ").add_to(tap_in_am_map)\n",
        "\n",
        "# Display the map\n",
        "tap_in_am_map.save(\"tap_in_volume_map.html\")\n",
        "\n",
        "# Initialize map centered around Singapore\n",
        "tap_out_am_map = folium.Map(location=[1.3521, 103.8198], zoom_start=11)\n",
        "\n",
        "# Add choropleth layer for total tap-in volume\n",
        "Choropleth(\n",
        "    geo_data=tap_out_am_geojson,\n",
        "    data=tap_out_am,\n",
        "    columns=['Name', 'total_tap_out_volume_am'],\n",
        "    key_on='feature.properties.Name',\n",
        "    fill_color='YlGnBu',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name='Total Tap-Out Volume AM',\n",
        ").add_to(tap_out_am_map)\n",
        "\n",
        "# Display the map\n",
        "tap_out_am_map.save(\"tap_out_volume_map.html\")\n",
        "# tap_out_am_map\n",
        "\n",
        "tap_in_am_map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accessibility map"
      ],
      "metadata": {
        "id": "BiYLwaa9yepP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzJsAq9pigVj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert bus stops to GeoDataFrame\n",
        "bus_stops['geometry'] = bus_stops.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
        "bus_stops_gdf = gpd.GeoDataFrame(bus_stops, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "# Convert MRT stations to GeoDataFrame\n",
        "mrt_stations['geometry'] = mrt_stations.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
        "mrt_stations_gdf = gpd.GeoDataFrame(mrt_stations, geometry='geometry', crs=\"EPSG:4326\")\n",
        "\n",
        "\n",
        "# Ensure the planning areas are in a projected CRS for area calculations (e.g., UTM zone 48N for Singapore)\n",
        "# You may need to replace 'epsg:32648' with the CRS suitable for your data location.\n",
        "planning_areas = planning_areas.to_crs(epsg=32648)\n",
        "\n",
        "# Calculate area in square kilometers\n",
        "planning_areas['area_sq_km'] = planning_areas['geometry'].area / 1e6  # Convert from square meters to square km\n",
        "\n",
        "# Reproject MRT stations and bus stops to match the planning areas CRS (EPSG:32648)\n",
        "mrt_stations_gdf = mrt_stations_gdf.to_crs(epsg=32648)\n",
        "bus_stops_gdf = bus_stops_gdf.to_crs(epsg=32648)\n",
        "\n",
        "# Now proceed with the spatial joins\n",
        "mrt_within_areas = gpd.sjoin(mrt_stations_gdf, planning_areas, how=\"inner\", predicate=\"within\")\n",
        "mrt_counts = mrt_within_areas.groupby('Name').size().reset_index(name='mrt_count')\n",
        "\n",
        "bus_within_areas = gpd.sjoin(bus_stops_gdf, planning_areas, how=\"inner\", predicate=\"within\")\n",
        "bus_counts = bus_within_areas.groupby('Name').size().reset_index(name='bus_count')\n",
        "\n",
        "# Merge counts with planning areas and continue with the rest of the steps\n",
        "accessibility = planning_areas.merge(mrt_counts, on=\"Name\", how=\"left\")\n",
        "accessibility = accessibility.merge(bus_counts, on=\"Name\", how=\"left\")\n",
        "\n",
        "# Fill NaN with 0 and calculate densities\n",
        "accessibility[['mrt_count', 'bus_count']] = accessibility[['mrt_count', 'bus_count']].fillna(0)\n",
        "accessibility['mrt_density'] = accessibility['mrt_count'] / accessibility['area_sq_km']\n",
        "accessibility['bus_density'] = accessibility['bus_count'] / accessibility['area_sq_km']\n",
        "accessibility['normalized_accessibility_index'] = accessibility['mrt_density'] + accessibility['bus_density']\n",
        "\n",
        "\n",
        "import folium\n",
        "from folium import Choropleth\n",
        "\n",
        "# Convert GeoDataFrame to GeoJSON\n",
        "accessibility_geojson = accessibility.to_crs(epsg=4326).to_json()\n",
        "\n",
        "# Initialize map centered around Singapore\n",
        "m = folium.Map(location=[1.3521, 103.8198], zoom_start=11)\n",
        "\n",
        "# Add choropleth layer for accessibility index\n",
        "Choropleth(\n",
        "    geo_data=accessibility_geojson,\n",
        "    data=accessibility,\n",
        "    columns=['Name', 'normalized_accessibility_index'],\n",
        "    key_on='feature.properties.Name',\n",
        "    fill_color='YlGnBu',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name='Accessibility Index',\n",
        ").add_to(m)\n",
        "\n",
        "# Display the map\n",
        "m.save(\"accessibility_map.html\")\n",
        "\n",
        "m\n",
        "\n",
        "print(accessibility.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmY9Lx4CigVj"
      },
      "outputs": [],
      "source": [
        "def get_passenger_demand(bus_routes_combined, passenger_volume, year_month, service_no):\n",
        "    # Filter the passenger_volume DataFrame\n",
        "    passenger_volume_am = passenger_volume[\n",
        "        (passenger_volume['TIME_PER_HOUR'].isin([8, 9])) &\n",
        "        (passenger_volume[\"DAY_TYPE\"] == \"WEEKDAY\") &\n",
        "        (passenger_volume['YEAR_MONTH'] == year_month)\n",
        "    ]\n",
        "\n",
        "    # Group by PT_CODE and sum the relevant passenger volumes\n",
        "    passenger_volume_am = passenger_volume_am.groupby('PT_CODE').agg({\n",
        "        'TOTAL_TAP_IN_VOLUME': 'sum',\n",
        "        'TOTAL_TAP_OUT_VOLUME': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Count the number of services for each bus stop\n",
        "    service_counts = bus_routes_combined.groupby('BusStopCode')['ServiceNo'].nunique().reset_index()\n",
        "    service_counts.columns = ['BusStopCode', 'ServiceCount']\n",
        "\n",
        "    avg_tap_volume = pd.merge(service_counts, passenger_volume_am, left_on=\"BusStopCode\", right_on='PT_CODE', how='left')\n",
        "\n",
        "    # Clean up duplicate PT_CODE columns (from both merges)\n",
        "    avg_tap_volume.drop(columns=['PT_CODE'], inplace=True)\n",
        "\n",
        "    avg_tap_volume['avg_tap_in'] = avg_tap_volume['TOTAL_TAP_IN_VOLUME'] / avg_tap_volume['ServiceCount']\n",
        "    avg_tap_volume['avg_tap_out'] = avg_tap_volume['TOTAL_TAP_OUT_VOLUME'] / avg_tap_volume['ServiceCount']\n",
        "\n",
        "    # Fill NaN values with 0 for average calculations\n",
        "    avg_tap_volume.fillna(0, inplace=True)\n",
        "\n",
        "    avg_tap_volume['avg_tap_in'] = avg_tap_volume['avg_tap_in'].round().astype(int)\n",
        "    avg_tap_volume['avg_tap_out'] = avg_tap_volume['avg_tap_out'].round().astype(int)\n",
        "\n",
        "    bus_stops_passenger_demand = bus_routes_combined.merge(\n",
        "        avg_tap_volume, on='BusStopCode', how='left'\n",
        "    )\n",
        "\n",
        "    # Filter for the specified service number and direction (1)\n",
        "    passenger_demand = bus_stops_passenger_demand[\n",
        "        (bus_stops_passenger_demand['ServiceNo'] == service_no) &\n",
        "        (bus_stops_passenger_demand['Direction'] == 1)\n",
        "    ]\n",
        "\n",
        "    # Ensure the average tap-in volumes are rounded to whole numbers\n",
        "    passenger_demand['avg_tap_in'] = passenger_demand['avg_tap_in'].round()\n",
        "    passenger_demand['avg_tap_out'] = passenger_demand['avg_tap_out'].round()\n",
        "\n",
        "    # Set the last observation of avg_tap_in to 0\n",
        "    passenger_demand['avg_tap_in'].iloc[-1] = 0\n",
        "    passenger_demand['avg_tap_out'].iloc[0] = 0\n",
        "\n",
        "    # Sort the DataFrame by StopSequence for ordered plotting\n",
        "    passenger_demand = passenger_demand.sort_values(by='StopSequence')\n",
        "\n",
        "    # Convert BusStopCode to a categorical variable ordered by StopSequence\n",
        "    passenger_demand['BusStopCode'] = pd.Categorical(passenger_demand['BusStopCode'],\n",
        "                                                       categories=passenger_demand['BusStopCode'].unique(),\n",
        "                                                       ordered=True)\n",
        "\n",
        "    return passenger_demand\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rFx1IRuigVk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get passenger demand data for the three months\n",
        "service_no = \"36B\"\n",
        "passenger_demand_36B_jul = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-07\", service_no)\n",
        "passenger_demand_36B_aug = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-08\", service_no)\n",
        "passenger_demand_36B_sept = get_passenger_demand(bus_routes_combined, passenger_volume, \"2024-09\", service_no)\n",
        "\n",
        "# Create side-by-side subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot average tap-in volumes\n",
        "axs[0].plot(range(len(passenger_demand_36B_jul)), passenger_demand_36B_jul['avg_tap_in'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[0].plot(range(len(passenger_demand_36B_aug)), passenger_demand_36B_aug['avg_tap_in'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[0].plot(range(len(passenger_demand_36B_sept)), passenger_demand_36B_sept['avg_tap_in'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-in plot\n",
        "axs[0].set_xlabel('Bus Stop Code')\n",
        "axs[0].set_ylabel('Average Tap-In Volume')\n",
        "axs[0].set_title('Average Tap-In Volume for Bus Service 36B by Stop Sequence')\n",
        "axs[0].set_xticks(range(len(passenger_demand_36B_jul)))\n",
        "axs[0].set_xticklabels(passenger_demand_36B_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[0].grid(axis='y')\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot average tap-out volumes\n",
        "axs[1].plot(range(len(passenger_demand_36B_jul)), passenger_demand_36B_jul['avg_tap_out'], marker='o', color='blue', linestyle='-', label='July')\n",
        "axs[1].plot(range(len(passenger_demand_36B_aug)), passenger_demand_36B_aug['avg_tap_out'], marker='o', color='orange', linestyle='-', label='August')\n",
        "axs[1].plot(range(len(passenger_demand_36B_sept)), passenger_demand_36B_sept['avg_tap_out'], marker='o', color='green', linestyle='-', label='September')\n",
        "\n",
        "# Add labels and title for tap-out plot\n",
        "axs[1].set_xlabel('Bus Stop Code')\n",
        "axs[1].set_ylabel('Average Tap-Out Volume')\n",
        "axs[1].set_title('Average Tap-Out Volume for Bus Service 36B by Stop Sequence')\n",
        "axs[1].set_xticks(range(len(passenger_demand_36B_jul)))\n",
        "axs[1].set_xticklabels(passenger_demand_36B_jul['BusStopCode'],  rotation=90, ha='right')\n",
        "axs[1].grid(axis='y')\n",
        "axs[1].legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo9j0ciNigVk"
      },
      "outputs": [],
      "source": [
        "\n",
        "passenger_volume_OD = passenger_volume_OD[\n",
        "        (passenger_volume_OD['TIME_PER_HOUR'].isin([8, 9])) &\n",
        "        (passenger_volume_OD[\"DAY_TYPE\"] == \"WEEKDAY\") &\n",
        "        (passenger_volume_OD['YEAR_MONTH'] == \"2024-09\")\n",
        "    ]\n",
        "\n",
        "    # Group by PT_CODE and sum the relevant passenger volumes\n",
        "passenger_volume_OD = passenger_volume_OD.groupby(['ORIGIN_PT_CODE', 'DESTINATION_PT_CODE']).agg({\n",
        "    'TOTAL_TRIPS': 'sum',\n",
        "}).reset_index()\n",
        "\n",
        "    # Count the number of services for each bus stop\n",
        "service_counts = bus_routes_combined.groupby('BusStopCode')['ServiceNo'].nunique().reset_index()\n",
        "service_counts.columns = ['BusStopCode', 'ServiceCount']\n",
        "\n",
        "avg_tap_volume = pd.merge(service_counts, passenger_volume_am, left_on=\"BusStopCode\", right_on='PT_CODE', how='left')\n",
        "\n",
        "od_pairs = []\n",
        "\n",
        "bus_stops_36B = bus_routes_combined[\n",
        "        (bus_routes_combined['ServiceNo'] == service_no) &\n",
        "        (bus_routes_combined['Direction'] == 1)\n",
        "    ]\n",
        "\n",
        "# Generate pairs of bus stops\n",
        "for (i, row1), (j, row2) in combinations(bus_stops_36B.iterrows(), 2):\n",
        "    if row1['StopSequence'] < row2['StopSequence']:  # Ensure origin has a smaller StopSequence\n",
        "        od_pairs.append((row1['BusStopCode'], row2['BusStopCode']))\n",
        "\n",
        "# Convert the list of pairs to a DataFrame\n",
        "od_pairs_df = pd.DataFrame(od_pairs, columns=['Origin', 'Destination'])\n",
        "\n",
        "# Display the resulting DataFrame of origin-destination pairs\n",
        "# print(od_pairs_df)\n",
        "\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "\n",
        "# Assuming bus_routes_combined is your DataFrame and service_no is defined\n",
        "service_no = \"36B\"\n",
        "\n",
        "# Filter for bus stops for service '36B' in the specified direction (1)\n",
        "bus_stops_36B = bus_routes_combined[\n",
        "    (bus_routes_combined['ServiceNo'] == service_no) &\n",
        "    (bus_routes_combined['Direction'] == 1)\n",
        "]\n",
        "\n",
        "# Generate pairs of bus stops\n",
        "od_pairs = []\n",
        "for (i, row1), (j, row2) in combinations(bus_stops_36B.iterrows(), 2):\n",
        "    if row1['StopSequence'] < row2['StopSequence']:  # Ensure origin has a smaller StopSequence\n",
        "        od_pairs.append((row1['BusStopCode'], row2['BusStopCode']))\n",
        "\n",
        "# Convert the list of pairs to a DataFrame\n",
        "od_pairs_df = pd.DataFrame(od_pairs, columns=['Origin', 'Destination'])\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# For each OD pair, find the count of unique services\n",
        "for index, row in od_pairs_df.iterrows():\n",
        "    origin = row['Origin']\n",
        "    destination = row['Destination']\n",
        "\n",
        "    # Filter services that go through both origin and destination\n",
        "    services_count = bus_routes_combined[\n",
        "        ((bus_routes_combined['BusStopCode'] == origin) | (bus_routes_combined['BusStopCode'] == destination))\n",
        "    ]['ServiceNo'].nunique()  # Count unique services\n",
        "\n",
        "    # Append the result\n",
        "    results.append((origin, destination, services_count))\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "results_df = pd.DataFrame(results, columns=['Origin', 'Destination', 'ServiceCount'])\n",
        "\n",
        "# Display the results\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "High demand origins and destinations"
      ],
      "metadata": {
        "id": "WVUzpNey4KKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the OD dataset\n",
        "od_data = pd.read_csv('data/passenger_volume_OD.csv')\n",
        "# Total trips by origin bus stop\n",
        "origin_demand = od_data.groupby('ORIGIN_PT_CODE')['TOTAL_TRIPS'].sum().reset_index()\n",
        "origin_demand.rename(columns={'TOTAL_TRIPS': 'TOTAL_TRIPS_FROM_ORIGIN'}, inplace=True)\n",
        "\n",
        "# Total trips by destination bus stop\n",
        "destination_demand = od_data.groupby('DESTINATION_PT_CODE')['TOTAL_TRIPS'].sum().reset_index()\n",
        "destination_demand.rename(columns={'TOTAL_TRIPS': 'TOTAL_TRIPS_TO_DESTINATION'}, inplace=True)\n",
        "\n",
        "# Calculate threshold (for example, 75th percentile)\n",
        "origin_threshold = origin_demand['TOTAL_TRIPS_FROM_ORIGIN'].quantile(0.90)\n",
        "destination_threshold = destination_demand['TOTAL_TRIPS_TO_DESTINATION'].quantile(0.90)\n",
        "\n",
        "# Identify high-demand origins and destinations\n",
        "high_demand_origins = origin_demand[origin_demand['TOTAL_TRIPS_FROM_ORIGIN'] >= origin_threshold]\n",
        "high_demand_destinations = destination_demand[destination_demand['TOTAL_TRIPS_TO_DESTINATION'] >= destination_threshold]\n",
        "\n",
        "# Merge high-demand origins with coordinates\n",
        "high_demand_origins = high_demand_origins.merge(bus_stops, left_on='ORIGIN_PT_CODE', right_on='BusStopCode', how='left')\n",
        "\n",
        "# Merge high-demand destinations with coordinates\n",
        "high_demand_destinations = high_demand_destinations.merge(bus_stops, left_on='DESTINATION_PT_CODE', right_on='BusStopCode', how='left')\n",
        "\n",
        "# Convert origins and destinations into GeoDataFrames\n",
        "# Assuming you have their coordinates (e.g., latitude and longitude) in the DataFrame\n",
        "origins_gdf = gpd.GeoDataFrame(high_demand_origins, geometry=gpd.points_from_xy(high_demand_origins.Longitude, high_demand_origins.Latitude), crs='EPSG:4326')\n",
        "destinations_gdf = gpd.GeoDataFrame(high_demand_destinations, geometry=gpd.points_from_xy(high_demand_destinations.Longitude, high_demand_destinations.Latitude), crs='EPSG:4326')\n",
        "\n",
        "# Set the same CRS for planning areas, origins, and destinations if they differ\n",
        "planning_areas = planning_areas.to_crs(epsg=4326)\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "planning_areas.plot(ax=ax, color='lightgrey', edgecolor='black')\n",
        "origins_gdf.plot(ax=ax, color='blue', marker='o', markersize=50, label='High Demand Origins')\n",
        "destinations_gdf.plot(ax=ax, color='red', marker='x', markersize=50, label='High Demand Destinations')\n",
        "\n",
        "plt.title('High Demand Origins and Destinations in Singapore')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EKEyi7co4N8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "heatmap"
      ],
      "metadata": {
        "id": "puWFaMsN4Vr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Combine origins and destinations into one DataFrame\n",
        "heat_data = pd.concat([\n",
        "    high_demand_origins[['Latitude', 'Longitude']],\n",
        "    high_demand_destinations[['Latitude', 'Longitude']]\n",
        "], ignore_index=True)\n",
        "\n",
        "# Create a base map\n",
        "singapore_map = folium.Map(location=[1.3521, 103.8198], zoom_start=12)  # Centered on Singapore\n",
        "\n",
        "# Prepare data for heatmap\n",
        "heat_data = [[row['Latitude'], row['Longitude']] for index, row in heat_data.iterrows()]\n",
        "\n",
        "# Create a heatmap layer\n",
        "HeatMap(heat_data, radius=15, blur=10).add_to(singapore_map)\n",
        "\n",
        "# Save the map to an HTML file or display it in a Jupyter notebook\n",
        "singapore_map.save(\"singapore_heatmap.html\")\n",
        "singapore_map\n"
      ],
      "metadata": {
        "id": "TmzhTXA04YJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}